Namespace(n_epochs=2000, batch_size=256, lr=0.001, loss_fn='BCE', break_epoch=30, act_fn='Tanh', a_y=1.0, a_r=1.0, a_d=1.0, a_f=0.15, u_kl=1.0, u_dim=7, run=4, gpu=0, rep=0, use_label=False, use_real=False, normalize=True, path=False, path_attribute='GPA', retrain=True, debug=True, test=True, tSNE=True, clf=True, balance=False, early_stop=True, dataset='law', seed=4, device='cuda', save_path='/users/PAS2334/zzz/CF_Fairness/CF_Representation/CVAE/law_result/a_r_1.0_a_d_1.0_a_y_1.0_a_f_0.15_u_7_run_4_use_label_False')
This code uses cuda
Epoch 0
###Train###
BCE(x): 7.7656
KL(u): 0.9517

###Valid###
BCE(x): 6.6461
KL(s): 0.7523
Epoch 1
###Train###
BCE(x): 6.3816
KL(u): 0.7214

###Valid###
BCE(x): 5.5381
KL(s): 0.7113
Epoch 2
###Train###
BCE(x): 5.2533
KL(u): 0.7860

###Valid###
BCE(x): 4.5587
KL(s): 0.8399
Epoch 3
###Train###
BCE(x): 4.3313
KL(u): 0.8981

###Valid###
BCE(x): 3.8136
KL(s): 0.9059
Epoch 4
###Train###
BCE(x): 3.7254
KL(u): 0.9490

###Valid###
BCE(x): 3.3384
KL(s): 0.9079
Epoch 5
###Train###
BCE(x): 3.3443
KL(u): 0.9376

###Valid###
BCE(x): 3.0885
KL(s): 0.9104
Epoch 6
###Train###
BCE(x): 3.0903
KL(u): 0.9419

###Valid###
BCE(x): 2.8616
KL(s): 0.8889
Epoch 7
###Train###
BCE(x): 2.9227
KL(u): 0.9060

###Valid###
BCE(x): 2.6914
KL(s): 0.8631
Epoch 8
###Train###
BCE(x): 2.7824
KL(u): 0.8560

###Valid###
BCE(x): 2.5912
KL(s): 0.8351
Epoch 9
###Train###
BCE(x): 2.6722
KL(u): 0.8371

###Valid###
BCE(x): 2.5253
KL(s): 0.7872
Epoch 10
###Train###
BCE(x): 2.5911
KL(u): 0.7934

###Valid###
BCE(x): 2.4066
KL(s): 0.7554
Epoch 11
###Train###
BCE(x): 2.4942
KL(u): 0.7594

###Valid###
BCE(x): 2.3563
KL(s): 0.7205
Epoch 12
###Train###
BCE(x): 2.4229
KL(u): 0.7249

###Valid###
BCE(x): 2.2886
KL(s): 0.6870
Epoch 13
###Train###
BCE(x): 2.3511
KL(u): 0.6993

###Valid###
BCE(x): 2.2159
KL(s): 0.6607
Epoch 14
###Train###
BCE(x): 2.2840
KL(u): 0.6728

###Valid###
BCE(x): 2.1434
KL(s): 0.6428
Epoch 15
###Train###
BCE(x): 2.2354
KL(u): 0.6528

###Valid###
BCE(x): 2.1157
KL(s): 0.6289
Epoch 16
###Train###
BCE(x): 2.1753
KL(u): 0.6473

###Valid###
BCE(x): 2.0755
KL(s): 0.6188
Epoch 17
###Train###
BCE(x): 2.1536
KL(u): 0.6409

###Valid###
BCE(x): 2.0108
KL(s): 0.6241
Epoch 18
###Train###
BCE(x): 2.1206
KL(u): 0.6415

###Valid###
BCE(x): 1.9911
KL(s): 0.6183
Epoch 19
###Train###
BCE(x): 2.0979
KL(u): 0.6264

###Valid###
BCE(x): 2.0123
KL(s): 0.6052
Epoch 20
###Train###
BCE(x): 2.0802
KL(u): 0.6198

###Valid###
BCE(x): 1.9651
KL(s): 0.6031
Epoch 21
###Train###
BCE(x): 2.0662
KL(u): 0.6234

###Valid###
BCE(x): 1.9340
KL(s): 0.6091
Epoch 22
###Train###
BCE(x): 2.0526
KL(u): 0.6365

###Valid###
BCE(x): 1.9465
KL(s): 0.6186
Epoch 23
###Train###
BCE(x): 2.0419
KL(u): 0.6348

###Valid###
BCE(x): 1.9042
KL(s): 0.6161
Epoch 24
###Train###
BCE(x): 2.0070
KL(u): 0.6370

###Valid###
BCE(x): 1.9119
KL(s): 0.6111
Epoch 25
###Train###
BCE(x): 2.0070
KL(u): 0.6424

###Valid###
BCE(x): 1.8950
KL(s): 0.6218
Epoch 26
###Train###
BCE(x): 1.9906
KL(u): 0.6430

###Valid###
BCE(x): 1.8478
KL(s): 0.6401
Epoch 27
###Train###
BCE(x): 1.9699
KL(u): 0.6608

###Valid###
BCE(x): 1.8756
KL(s): 0.6407
Epoch 28
###Train###
BCE(x): 1.9612
KL(u): 0.6671

###Valid###
BCE(x): 1.8420
KL(s): 0.6494
Epoch 29
###Train###
BCE(x): 1.9413
KL(u): 0.6726

###Valid###
BCE(x): 1.8437
KL(s): 0.6601
Epoch 30
###Train###
BCE(x): 1.9382
KL(u): 0.6840

###Valid###
BCE(x): 1.8061
KL(s): 0.6604
Epoch 31
###Train###
BCE(x): 1.9283
KL(u): 0.6864

###Valid###
BCE(x): 1.8190
KL(s): 0.6644
Epoch 32
###Train###
BCE(x): 1.9142
KL(u): 0.6876

###Valid###
BCE(x): 1.8304
KL(s): 0.6691
Epoch 33
###Train###
BCE(x): 1.9034
KL(u): 0.6919

###Valid###
BCE(x): 1.7947
KL(s): 0.6797
Epoch 34
###Train###
BCE(x): 1.8991
KL(u): 0.7106

###Valid###
BCE(x): 1.7975
KL(s): 0.6885
Epoch 35
###Train###
BCE(x): 1.8905
KL(u): 0.7089

###Valid###
BCE(x): 1.7824
KL(s): 0.6942
Epoch 36
###Train###
BCE(x): 1.8702
KL(u): 0.7144

###Valid###
BCE(x): 1.7739
KL(s): 0.6920
Epoch 37
###Train###
BCE(x): 1.8709
KL(u): 0.7181

###Valid###
BCE(x): 1.7659
KL(s): 0.6988
Epoch 38
###Train###
BCE(x): 1.8617
KL(u): 0.7235

###Valid###
BCE(x): 1.7686
KL(s): 0.6961
Epoch 39
###Train###
BCE(x): 1.8650
KL(u): 0.7205

###Valid###
BCE(x): 1.7838
KL(s): 0.6956
Epoch 40
###Train###
BCE(x): 1.8490
KL(u): 0.7275

###Valid###
BCE(x): 1.7504
KL(s): 0.6913
Epoch 41
###Train###
BCE(x): 1.8613
KL(u): 0.7241

###Valid###
BCE(x): 1.7247
KL(s): 0.7181
Epoch 42
###Train###
BCE(x): 1.8303
KL(u): 0.7395

###Valid###
BCE(x): 1.7361
KL(s): 0.6987
Epoch 43
###Train###
BCE(x): 1.8495
KL(u): 0.7352

###Valid###
BCE(x): 1.7146
KL(s): 0.7186
Epoch 44
###Train###
BCE(x): 1.8254
KL(u): 0.7440

###Valid###
BCE(x): 1.7153
KL(s): 0.7248
Epoch 45
###Train###
BCE(x): 1.8316
KL(u): 0.7567

###Valid###
BCE(x): 1.7194
KL(s): 0.7210
Epoch 46
###Train###
BCE(x): 1.8178
KL(u): 0.7408

###Valid###
BCE(x): 1.6935
KL(s): 0.7271
Epoch 47
###Train###
BCE(x): 1.8066
KL(u): 0.7560

###Valid###
BCE(x): 1.7227
KL(s): 0.7302
Epoch 48
###Train###
BCE(x): 1.8026
KL(u): 0.7683

###Valid###
BCE(x): 1.6832
KL(s): 0.7491
Epoch 49
###Train###
BCE(x): 1.7977
KL(u): 0.7681

###Valid###
BCE(x): 1.6792
KL(s): 0.7569
Epoch 50
###Train###
BCE(x): 1.7826
KL(u): 0.7802

###Valid###
BCE(x): 1.7054
KL(s): 0.7585
Epoch 51
###Train###
BCE(x): 1.7762
KL(u): 0.7683

###Valid###
BCE(x): 1.6812
KL(s): 0.7510
Epoch 52
###Train###
BCE(x): 1.7655
KL(u): 0.7872

###Valid###
BCE(x): 1.6700
KL(s): 0.7624
Epoch 53
###Train###
BCE(x): 1.7540
KL(u): 0.7981

###Valid###
BCE(x): 1.6710
KL(s): 0.7776
Epoch 54
###Train###
BCE(x): 1.7357
KL(u): 0.8119

###Valid###
BCE(x): 1.6312
KL(s): 0.7887
Epoch 55
###Train###
BCE(x): 1.7229
KL(u): 0.8214

###Valid###
BCE(x): 1.6085
KL(s): 0.7847
Epoch 56
###Train###
BCE(x): 1.7186
KL(u): 0.8184

###Valid###
BCE(x): 1.6277
KL(s): 0.7966
Epoch 57
###Train###
BCE(x): 1.7034
KL(u): 0.8273

###Valid###
BCE(x): 1.6243
KL(s): 0.7931
Epoch 58
###Train###
BCE(x): 1.7037
KL(u): 0.8246

###Valid###
BCE(x): 1.6239
KL(s): 0.8092
Epoch 59
###Train###
BCE(x): 1.7012
KL(u): 0.8454

###Valid###
BCE(x): 1.5934
KL(s): 0.8148
Epoch 60
###Train###
BCE(x): 1.6976
KL(u): 0.8378

###Valid###
BCE(x): 1.6194
KL(s): 0.8089
Epoch 61
###Train###
BCE(x): 1.6878
KL(u): 0.8556

###Valid###
BCE(x): 1.5912
KL(s): 0.8342
Epoch 62
###Train###
BCE(x): 1.6621
KL(u): 0.8523

###Valid###
BCE(x): 1.6036
KL(s): 0.8257
Epoch 63
###Train###
BCE(x): 1.6614
KL(u): 0.8471

###Valid###
BCE(x): 1.6005
KL(s): 0.8164
Epoch 64
###Train###
BCE(x): 1.6688
KL(u): 0.8562

###Valid###
BCE(x): 1.5424
KL(s): 0.8390
Epoch 65
###Train###
BCE(x): 1.6542
KL(u): 0.8644

###Valid###
BCE(x): 1.5688
KL(s): 0.8357
Epoch 66
###Train###
BCE(x): 1.6517
KL(u): 0.8648

###Valid###
BCE(x): 1.5583
KL(s): 0.8416
Epoch 67
###Train###
BCE(x): 1.6529
KL(u): 0.8712

###Valid###
BCE(x): 1.5643
KL(s): 0.8385
Epoch 68
###Train###
BCE(x): 1.6395
KL(u): 0.8737

###Valid###
BCE(x): 1.5555
KL(s): 0.8539
Epoch 69
###Train###
BCE(x): 1.6301
KL(u): 0.8701

###Valid###
BCE(x): 1.5534
KL(s): 0.8452
Epoch 70
###Train###
BCE(x): 1.6212
KL(u): 0.8856

###Valid###
BCE(x): 1.5186
KL(s): 0.8718
Epoch 71
###Train###
BCE(x): 1.6183
KL(u): 0.8860

###Valid###
BCE(x): 1.5404
KL(s): 0.8612
Epoch 72
###Train###
BCE(x): 1.6158
KL(u): 0.9036

###Valid###
BCE(x): 1.5281
KL(s): 0.8651
Epoch 73
###Train###
BCE(x): 1.6193
KL(u): 0.8910

###Valid###
BCE(x): 1.5057
KL(s): 0.8712
Epoch 74
###Train###
BCE(x): 1.6016
KL(u): 0.9141

###Valid###
BCE(x): 1.5557
KL(s): 0.8559
Epoch 75
###Train###
BCE(x): 1.6058
KL(u): 0.9045

###Valid###
BCE(x): 1.4809
KL(s): 0.8802
Epoch 76
###Train###
BCE(x): 1.5853
KL(u): 0.9188

###Valid###
BCE(x): 1.4992
KL(s): 0.8961
Epoch 77
###Train###
BCE(x): 1.5948
KL(u): 0.9132

###Valid###
BCE(x): 1.5165
KL(s): 0.8737
Epoch 78
###Train###
BCE(x): 1.5892
KL(u): 0.9058

###Valid###
BCE(x): 1.5234
KL(s): 0.8642
Epoch 79
###Train###
BCE(x): 1.5872
KL(u): 0.9056

###Valid###
BCE(x): 1.5060
KL(s): 0.8779
Epoch 80
###Train###
BCE(x): 1.5774
KL(u): 0.9175

###Valid###
BCE(x): 1.5064
KL(s): 0.8773
Epoch 81
###Train###
BCE(x): 1.5742
KL(u): 0.9197

###Valid###
BCE(x): 1.4945
KL(s): 0.8932
Epoch 82
###Train###
BCE(x): 1.5722
KL(u): 0.9331

###Valid###
BCE(x): 1.4741
KL(s): 0.8978
Epoch 83
###Train###
BCE(x): 1.5743
KL(u): 0.9221

###Valid###
BCE(x): 1.4605
KL(s): 0.9084
Epoch 84
###Train###
BCE(x): 1.5600
KL(u): 0.9244

###Valid###
BCE(x): 1.4680
KL(s): 0.8950
Epoch 85
###Train###
BCE(x): 1.5617
KL(u): 0.9275

###Valid###
BCE(x): 1.4748
KL(s): 0.9005
Epoch 86
###Train###
BCE(x): 1.5550
KL(u): 0.9265

###Valid###
BCE(x): 1.4578
KL(s): 0.8866
Epoch 87
###Train###
BCE(x): 1.5540
KL(u): 0.9278

###Valid###
BCE(x): 1.4631
KL(s): 0.8976
Epoch 88
###Train###
BCE(x): 1.5504
KL(u): 0.9298

###Valid###
BCE(x): 1.4673
KL(s): 0.8978
Epoch 89
###Train###
BCE(x): 1.5574
KL(u): 0.9339

###Valid###
BCE(x): 1.4828
KL(s): 0.8863
Epoch 90
###Train###
BCE(x): 1.5561
KL(u): 0.9297

###Valid###
BCE(x): 1.4531
KL(s): 0.9063
Epoch 91
###Train###
BCE(x): 1.5495
KL(u): 0.9313

###Valid###
BCE(x): 1.4608
KL(s): 0.8990
Epoch 92
###Train###
BCE(x): 1.5496
KL(u): 0.9312

###Valid###
BCE(x): 1.4517
KL(s): 0.9119
Epoch 93
###Train###
BCE(x): 1.5407
KL(u): 0.9393

###Valid###
BCE(x): 1.4617
KL(s): 0.9134
Epoch 94
###Train###
BCE(x): 1.5356
KL(u): 0.9456

###Valid###
BCE(x): 1.4705
KL(s): 0.8995
Epoch 95
###Train###
BCE(x): 1.5506
KL(u): 0.9368

###Valid###
BCE(x): 1.4810
KL(s): 0.9036
Epoch 96
###Train###
BCE(x): 1.5254
KL(u): 0.9389

###Valid###
BCE(x): 1.4767
KL(s): 0.8867
Epoch 97
###Train###
BCE(x): 1.5505
KL(u): 0.9466

###Valid###
BCE(x): 1.4423
KL(s): 0.9170
Epoch 98
###Train###
BCE(x): 1.5328
KL(u): 0.9427

###Valid###
BCE(x): 1.4709
KL(s): 0.9114
Epoch 99
###Train###
BCE(x): 1.5446
KL(u): 0.9426

###Valid###
BCE(x): 1.4482
KL(s): 0.9124
Epoch 100
###Train###
BCE(x): 1.5373
KL(u): 0.9435

###Valid###
BCE(x): 1.4554
KL(s): 0.9139
Epoch 101
###Train###
BCE(x): 1.5290
KL(u): 0.9331

###Valid###
BCE(x): 1.4670
KL(s): 0.8913
Epoch 102
###Train###
BCE(x): 1.5408
KL(u): 0.9490

###Valid###
BCE(x): 1.4159
KL(s): 0.9266
Epoch 103
###Train###
BCE(x): 1.5238
KL(u): 0.9531

###Valid###
BCE(x): 1.4718
KL(s): 0.9189
Epoch 104
###Train###
BCE(x): 1.5304
KL(u): 0.9451

###Valid###
BCE(x): 1.4428
KL(s): 0.9329
Epoch 105
###Train###
BCE(x): 1.5222
KL(u): 0.9525

###Valid###
BCE(x): 1.4407
KL(s): 0.9146
Epoch 106
###Train###
BCE(x): 1.5311
KL(u): 0.9438

###Valid###
BCE(x): 1.4534
KL(s): 0.9090
Epoch 107
###Train###
BCE(x): 1.5249
KL(u): 0.9480

###Valid###
BCE(x): 1.4572
KL(s): 0.9090
Epoch 108
###Train###
BCE(x): 1.5227
KL(u): 0.9448

###Valid###
BCE(x): 1.4474
KL(s): 0.9239
Epoch 109
###Train###
BCE(x): 1.5244
KL(u): 0.9439

###Valid###
BCE(x): 1.4537
KL(s): 0.9096
Epoch 110
###Train###
BCE(x): 1.5287
KL(u): 0.9528

###Valid###
BCE(x): 1.4266
KL(s): 0.9077
Epoch 111
###Train###
BCE(x): 1.5276
KL(u): 0.9556

###Valid###
BCE(x): 1.4544
KL(s): 0.9198
Epoch 112
###Train###
BCE(x): 1.5267
KL(u): 0.9528

###Valid###
BCE(x): 1.4126
KL(s): 0.9272
Epoch 113
###Train###
BCE(x): 1.5146
KL(u): 0.9459

###Valid###
BCE(x): 1.4378
KL(s): 0.9129
Epoch 114
###Train###
BCE(x): 1.5165
KL(u): 0.9495

###Valid###
BCE(x): 1.4440
KL(s): 0.9249
Epoch 115
###Train###
BCE(x): 1.5263
KL(u): 0.9563

###Valid###
BCE(x): 1.4380
KL(s): 0.8969
Epoch 116
###Train###
BCE(x): 1.5219
KL(u): 0.9497

###Valid###
BCE(x): 1.4216
KL(s): 0.9223
Epoch 117
###Train###
BCE(x): 1.5192
KL(u): 0.9543

###Valid###
BCE(x): 1.4082
KL(s): 0.9288
Epoch 118
###Train###
BCE(x): 1.5121
KL(u): 0.9726

###Valid###
BCE(x): 1.4541
KL(s): 0.9222
Epoch 119
###Train###
BCE(x): 1.5179
KL(u): 0.9611

###Valid###
BCE(x): 1.4018
KL(s): 0.9435
Epoch 120
###Train###
BCE(x): 1.5110
KL(u): 0.9696

###Valid###
BCE(x): 1.4341
KL(s): 0.9148
Epoch 121
###Train###
BCE(x): 1.5171
KL(u): 0.9634

###Valid###
BCE(x): 1.4234
KL(s): 0.9249
Epoch 122
###Train###
BCE(x): 1.5153
KL(u): 0.9592

###Valid###
BCE(x): 1.4402
KL(s): 0.9232
Epoch 123
###Train###
BCE(x): 1.5189
KL(u): 0.9602

###Valid###
BCE(x): 1.3976
KL(s): 0.9348
Epoch 124
###Train###
BCE(x): 1.5046
KL(u): 0.9598

###Valid###
BCE(x): 1.4399
KL(s): 0.9180
Epoch 125
###Train###
BCE(x): 1.5039
KL(u): 0.9573

###Valid###
BCE(x): 1.4507
KL(s): 0.8969
Epoch 126
###Train###
BCE(x): 1.5159
KL(u): 0.9570

###Valid###
BCE(x): 1.4494
KL(s): 0.9265
Epoch 127
###Train###
BCE(x): 1.5106
KL(u): 0.9668

###Valid###
BCE(x): 1.4194
KL(s): 0.9247
Epoch 128
###Train###
BCE(x): 1.5162
KL(u): 0.9481

###Valid###
BCE(x): 1.3748
KL(s): 0.9295
Epoch 129
###Train###
BCE(x): 1.5148
KL(u): 0.9520

###Valid###
BCE(x): 1.4161
KL(s): 0.9469
Epoch 130
###Train###
BCE(x): 1.5037
KL(u): 0.9688

###Valid###
BCE(x): 1.4126
KL(s): 0.9352
Epoch 131
###Train###
BCE(x): 1.5099
KL(u): 0.9588

###Valid###
BCE(x): 1.4230
KL(s): 0.9269
Epoch 132
###Train###
BCE(x): 1.5089
KL(u): 0.9644

###Valid###
BCE(x): 1.4257
KL(s): 0.9189
Epoch 133
###Train###
BCE(x): 1.5011
KL(u): 0.9626

###Valid###
BCE(x): 1.4089
KL(s): 0.9165
Epoch 134
###Train###
BCE(x): 1.5234
KL(u): 0.9584

###Valid###
BCE(x): 1.4615
KL(s): 0.9166
Epoch 135
###Train###
BCE(x): 1.5098
KL(u): 0.9574

###Valid###
BCE(x): 1.4481
KL(s): 0.9126
Epoch 136
###Train###
BCE(x): 1.5100
KL(u): 0.9617

###Valid###
BCE(x): 1.3849
KL(s): 0.9475
Epoch 137
###Train###
BCE(x): 1.4990
KL(u): 0.9635

###Valid###
BCE(x): 1.4217
KL(s): 0.9172
Epoch 138
###Train###
BCE(x): 1.4982
KL(u): 0.9585

###Valid###
BCE(x): 1.4380
KL(s): 0.9125
Epoch 139
###Train###
BCE(x): 1.5098
KL(u): 0.9660

###Valid###
BCE(x): 1.4081
KL(s): 0.9342
Epoch 140
###Train###
BCE(x): 1.4972
KL(u): 0.9808

###Valid###
BCE(x): 1.3984
KL(s): 0.9414
Epoch 141
###Train###
BCE(x): 1.4958
KL(u): 0.9613

###Valid###
BCE(x): 1.4262
KL(s): 0.9223
Epoch 142
###Train###
BCE(x): 1.5024
KL(u): 0.9589

###Valid###
BCE(x): 1.4149
KL(s): 0.9296
Epoch 143
###Train###
BCE(x): 1.5067
KL(u): 0.9631

###Valid###
BCE(x): 1.4239
KL(s): 0.9308
Epoch 144
###Train###
BCE(x): 1.4924
KL(u): 0.9595

###Valid###
BCE(x): 1.4002
KL(s): 0.9182
Epoch 145
###Train###
BCE(x): 1.5071
KL(u): 0.9732

###Valid###
BCE(x): 1.4047
KL(s): 0.9502
Epoch 146
###Train###
BCE(x): 1.4927
KL(u): 0.9647

###Valid###
BCE(x): 1.4340
KL(s): 0.9060
Epoch 147
###Train###
BCE(x): 1.5105
KL(u): 0.9539

###Valid###
BCE(x): 1.3994
KL(s): 0.9356
Epoch 148
###Train###
BCE(x): 1.4849
KL(u): 0.9633

###Valid###
BCE(x): 1.4252
KL(s): 0.9282
Epoch 149
###Train###
BCE(x): 1.4884
KL(u): 0.9669

###Valid###
BCE(x): 1.3960
KL(s): 0.9143
Epoch 150
###Train###
BCE(x): 1.4941
KL(u): 0.9577

###Valid###
BCE(x): 1.4088
KL(s): 0.9250
Epoch 151
###Train###
BCE(x): 1.4980
KL(u): 0.9705

###Valid###
BCE(x): 1.4326
KL(s): 0.9276
Epoch 152
###Train###
BCE(x): 1.4957
KL(u): 0.9678

###Valid###
BCE(x): 1.3845
KL(s): 0.9527
Epoch 153
###Train###
BCE(x): 1.4792
KL(u): 0.9713

###Valid###
BCE(x): 1.3745
KL(s): 0.9433
Epoch 154
###Train###
BCE(x): 1.4932
KL(u): 0.9714

###Valid###
BCE(x): 1.4137
KL(s): 0.9241
Epoch 155
###Train###
BCE(x): 1.4958
KL(u): 0.9714

###Valid###
BCE(x): 1.4117
KL(s): 0.9337
Epoch 156
###Train###
BCE(x): 1.4960
KL(u): 0.9647

###Valid###
BCE(x): 1.4232
KL(s): 0.9304
Epoch 157
###Train###
BCE(x): 1.4931
KL(u): 0.9790

###Valid###
BCE(x): 1.3681
KL(s): 0.9443
Epoch 158
###Train###
BCE(x): 1.4877
KL(u): 0.9699

###Valid###
BCE(x): 1.4159
KL(s): 0.9270
Epoch 159
###Train###
BCE(x): 1.4847
KL(u): 0.9678

###Valid###
BCE(x): 1.4085
KL(s): 0.9360
time elapsed: 4.8340min
best epoch for loss is 128

Namespace(n_epochs=2000, batch_size=256, lr=0.001, loss_fn='BCE', break_epoch=30, act_fn='Tanh', a_y=1.0, a_r=1.0, a_d=1.0, a_f=0.15, u_kl=1.0, u_dim=7, run=4, gpu=0, rep=0, use_label=False, use_real=False, normalize=True, path=False, path_attribute='GPA', retrain=False, debug=True, test=True, tSNE=True, clf=True, balance=False, early_stop=True, dataset='law', seed=4, device='cuda', save_path='/users/PAS2334/zzz/CF_Fairness/CF_Representation/CVAE/law_result/a_r_1.0_a_d_1.0_a_y_1.0_a_f_0.15_u_7_run_4_use_label_False')
This code uses cuda
Namespace(n_epochs=2000, batch_size=256, lr=0.001, loss_fn='BCE', break_epoch=30, act_fn='Tanh', a_y=1.0, a_r=1.0, a_d=1.0, a_f=0.15, u_kl=1.0, u_dim=7, run=4, gpu=0, rep=0, use_label=False, use_real=False, normalize=True, path=True, path_attribute='GPA', retrain=False, debug=True, test=True, tSNE=True, clf=True, balance=False, early_stop=True, dataset='law', seed=4, device='cuda', save_path='/users/PAS2334/zzz/CF_Fairness/CF_Representation/CVAE/law_result/a_r_1.0_a_d_1.0_a_y_1.0_a_f_0.15_u_7_run_4_use_label_False')
This code uses cuda
Namespace(n_epochs=2000, batch_size=256, lr=0.001, loss_fn='BCE', break_epoch=30, act_fn='Tanh', a_y=1.0, a_r=1.0, a_d=1.0, a_f=0.15, u_kl=1.0, u_dim=7, run=4, gpu=0, rep=0, use_label=False, use_real=False, normalize=True, path=True, path_attribute='SAT', retrain=False, debug=True, test=True, tSNE=True, clf=True, balance=False, early_stop=True, dataset='law', seed=4, device='cuda', save_path='/users/PAS2334/zzz/CF_Fairness/CF_Representation/CVAE/law_result/a_r_1.0_a_d_1.0_a_y_1.0_a_f_0.15_u_7_run_4_use_label_False')
This code uses cuda
